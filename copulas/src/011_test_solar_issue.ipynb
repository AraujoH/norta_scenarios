{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\ks885\\Documents\\aa_research\\Modeling\\norta_scenarios\\copulas\\src\\copulas`\n"
     ]
    }
   ],
   "source": [
    "# Scenario Generation with Copulas \n",
    "# \n",
    "# Hugo S. de Araujo\n",
    "# Nov. 14th, 2022 | Mays Group | Cornell University\n",
    "################################################################################\n",
    "\n",
    "#=======================================================================\n",
    "PROJECT SETUP\n",
    "=======================================================================#\n",
    "using Pkg\n",
    "Pkg.activate(\"copulas\");\n",
    "Pkg.instantiate();\n",
    "# Import \"here\" function. Wrapper to allow easy path concatenation.\n",
    "include(joinpath(@__DIR__, \"functions\", \"fct_here.jl\"))\n",
    "\n",
    "# Import all required packages. \n",
    "begin\n",
    "    # using AWSS3\n",
    "    using CSV\n",
    "    using DataFrames\n",
    "    using Dates\n",
    "    using DelimitedFiles\n",
    "    using Distributions\n",
    "    using HDF5\n",
    "    using JuliaFormatter\n",
    "    using LaTeXStrings\n",
    "    using LinearAlgebra\n",
    "    using LinearSolve\n",
    "    #using Measures\n",
    "    using Random\n",
    "    using RCall\n",
    "    using Revise\n",
    "    using Statistics\n",
    "    using StatsBase\n",
    "    #using StatsPlots\n",
    "    using OhMyREPL\n",
    "    using Plots\n",
    "    #using PrettyTables\n",
    "    using Tables\n",
    "    using TSFrames\n",
    "    using TimeZones\n",
    "end\n",
    "\n",
    "# Include functions \n",
    "#= functions_dirpath = joinpath(pwd(),\"src\", \"functions\");\n",
    "function_paths = readdir(functions_dirpath, join=true);\n",
    "function_index = occursin.(\".jl\", function_paths);\n",
    "functions_only = function_paths[function_index];\n",
    "\n",
    "for str in functions_only\n",
    "    include(str)\n",
    "end =#\n",
    "\n",
    "include(here(\"src\", \"functions\", \"fct_bind_historical_forecast.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_compute_hourly_average_actuals.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_compute_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_hours_2018.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_ISO_standard.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_land_prob_to_data.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_generate_probability_scenarios.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_getplots.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_correlation_heatmap.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_historical_landing.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_historical_synthetic_autocorrelation.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_correlogram_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_scenarios_and_actual.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_read_h5_file.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_read_input_file.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_transform_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_write_percentiles.jl\"));\n",
    "#=======================================================================\n",
    "READ INPUT FILE\n",
    "=======================================================================#\n",
    "input_file_path = here(\"src\\\\copulas.txt\")\n",
    "\n",
    "# XXX Needs to be updated to be a hardcoded instead of reading in a text file\n",
    "data_type,\n",
    "scenario_length,\n",
    "number_of_scenarios,\n",
    "scenario_hour,\n",
    "scenario_day,\n",
    "scenario_month,\n",
    "scenario_year,\n",
    "read_locally,\n",
    "historical_load,\n",
    "forecast_load,\n",
    "historical_solar,\n",
    "forecast_da_solar,\n",
    "forecast_2da_solar,\n",
    "historical_wind,\n",
    "forecastd_da_wind,\n",
    "forecast_2da_wind,\n",
    "write_percentile = read_input_file(input_file_path);\n",
    "\n",
    "#=======================================================================\n",
    "READ INPUT DATA: ARPA-E PERFORM PROJECT H5 FILES\n",
    "=======================================================================#\n",
    "# Function that reads the .h5 file and binds the time index and the actuals/fore-\n",
    "# cast values into a single dataframe.\n",
    "\n",
    "# Load data\n",
    "load_actuals_raw = read_h5_file(here(\"data\", historical_load), \"load\");\n",
    "load_forecast_raw = read_h5_file(here(\"data\", \"ercot_BA_load_forecast_day_ahead_2018.h5\"), \"load\", false);\n",
    "\n",
    "# Solar data\n",
    "solar_actuals_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_actuals_Existing_2018.h5\"), \"solar\");\n",
    "solar_forecast_dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_forecast_day_ahead_existing_2018.h5\"), \"solar\", false);\n",
    "solar_forecast_2dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_forecast_2_day_ahead_existing_2018.h5\"), \"solar\", false);\n",
    "\n",
    "# Wind data\n",
    "wind_actuals_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_actuals_Existing_2018.h5\"), \"wind\");\n",
    "wind_forecast_dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_forecast_day_ahead_existing_2018.h5\"), \"wind\", false);\n",
    "wind_forecast_2dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_forecast_2_day_ahead_existing_2018.h5\"), \"wind\", false);\n",
    "\n",
    "#=======================================================================\n",
    "Compute the hourly average for the actuals data\n",
    "=======================================================================#\n",
    "# Load\n",
    "aux = compute_hourly_average_actuals(load_actuals_raw);\n",
    "load_actual_avg_raw = DataFrame();\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "load_actual_avg_raw[!, :time_index] = time_index;\n",
    "load_actual_avg_raw[!, :avg_actual] = avg_actual;\n",
    "\n",
    "# Solar\n",
    "aux = compute_hourly_average_actuals(solar_actuals_raw);\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "solar_actual_avg_raw = DataFrame();\n",
    "solar_actual_avg_raw[!, :time_index] = time_index;\n",
    "solar_actual_avg_raw[!, :avg_actual] = avg_actual;\n",
    "\n",
    "# Wind\n",
    "aux = compute_hourly_average_actuals(wind_actuals_raw);\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "wind_actual_avg_raw = DataFrame();\n",
    "wind_actual_avg_raw[!, :time_index] = time_index;\n",
    "wind_actual_avg_raw[!, :avg_actual] = avg_actual;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upd_convert_hours_2018 (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a function to do this for all data\n",
    "function upd_convert_hours_2018(data, is_actual = true)\n",
    "    if is_actual\n",
    "        x = copy(data);\n",
    "        x[:,:time_index] = x[:,:time_index] .- Dates.Hour(6);\n",
    "        return x;\n",
    "    else\n",
    "        df = copy(data);\n",
    "        df[:,:forecast_time] = df[:,:forecast_time] .- Dates.Hour(6);\n",
    "        df[:,:issue_time] = df[:,:issue_time] .- Dates.Hour(6);\n",
    "        return df;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "load_actuals = upd_convert_hours_2018(load_actuals_raw);\n",
    "load_actual_avg = upd_convert_hours_2018(load_actual_avg_raw);\n",
    "load_forecast = upd_convert_hours_2018(load_forecast_raw, false);\n",
    "\n",
    "# Solar data\n",
    "solar_actuals = upd_convert_hours_2018(solar_actuals_raw);\n",
    "solar_actual_avg = upd_convert_hours_2018(solar_actual_avg_raw);\n",
    "solar_forecast_dayahead = upd_convert_hours_2018(solar_forecast_dayahead_raw, false);\n",
    "solar_forecast_2dayahead = upd_convert_hours_2018(solar_forecast_2dayahead_raw, false);\n",
    "\n",
    "# Wind data\n",
    "wind_actuals = upd_convert_hours_2018(wind_actuals_raw);\n",
    "wind_actual_avg = upd_convert_hours_2018(wind_actual_avg_raw);\n",
    "wind_forecast_dayahead = upd_convert_hours_2018(wind_forecast_dayahead_raw, false);\n",
    "wind_forecast_2dayahead = upd_convert_hours_2018(wind_forecast_2dayahead_raw, false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "BIND HOURLY HISTORICAL DATA WITH FORECAST DATA\n",
    "========================================================================#\n",
    "#= The binding is made by (\"forecast_time\" = \"time_index\"). This causes the \n",
    "average actual value to be duplicated, which is desired, given the # of rows\n",
    "in the load_forecast is double that of load_actual. To distinguish a \n",
    "one-day-ahead forecast from a two-day-ahead forecast, the column \"ahead_factor\"\n",
    "is introduced. Bind the day-ahead and two-day-ahead forecasts for wind and solar\n",
    "to get all the forecast data into one object as it is for load forecast =#\n",
    "    load_data = bind_historical_forecast(true,\n",
    "    load_actual_avg,\n",
    "    load_forecast);\n",
    "\n",
    "solar_data = bind_historical_forecast(false,\n",
    "    solar_actual_avg,\n",
    "    solar_forecast_dayahead,\n",
    "    solar_forecast_2dayahead);\n",
    "\n",
    "wind_data = bind_historical_forecast(false,\n",
    "    wind_actual_avg,\n",
    "    wind_forecast_dayahead,\n",
    "    wind_forecast_2dayahead);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "Landing probability\n",
    "=======================================================================#\n",
    "#= This section holds the calculation of the probability that the actual\n",
    "value was equaled or superior than the forecast percentiles for a given\n",
    "day. This is made possible by the estimation of an approximate CDF\n",
    "computed on the forecast percentiles. Once estimated, this function is\n",
    "used to find the \"landing probability\"; the prob. that the actual value\n",
    "is equal or greater than a % percentage of the forecast percentile.\n",
    "=#\n",
    "#include(here(\"src\", \"functions\", \"fct_compute_landing_probability.jl\"))\n",
    "landing_probability_load = compute_landing_probability(load_data);\n",
    "landing_probability_solar = compute_landing_probability(solar_data);\n",
    "landing_probability_wind = compute_landing_probability(wind_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "ADJUST LANDING PROBABILITY DATAFRAME\n",
    "=======================================================================#\n",
    "lp_load = transform_landing_probability(landing_probability_load);\n",
    "lp_solar = transform_landing_probability(landing_probability_solar);\n",
    "lp_wind = transform_landing_probability(landing_probability_wind);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "Determine length of Decision Problem\n",
    "=======================================================================#\n",
    "x = copy(wind_data);\n",
    "# Sort data by issue time\n",
    "sort!(x, :issue_time);\n",
    "# Group data by issue time and count occurences in every group\n",
    "df = combine(groupby(x, [:issue_time]), DataFrames.nrow => :count);\n",
    "# Filter data by count. Only keep groups with 48 entries\n",
    "df_filtered = filter(:count => ==(48), df);\n",
    "issue_times_interest = df_filtered[!, :issue_time];\n",
    "# find all forecast times for these issue times of interest\n",
    "subset_wind_data = filter(row -> row[:issue_time] in issue_times_interest, wind_data);\n",
    "subset_forecast_times = subset_wind_data[!, :forecast_time];\n",
    "unique_forecast_times = unique(subset_forecast_times);\n",
    "decision_T = length(unique_forecast_times);\n",
    "\n",
    "unique_issue_times = unique(subset_wind_data[!, :issue_time]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = copy(lp_solar)\n",
    "allequal_set = Set(findall(allequal, eachcol(x)));\n",
    "allequal_ind = sort(collect(allequal_set));\n",
    "allindex_set = Set(collect(1:48));\n",
    "alldifferent_ind = sort(collect(setdiff(allindex_set, allequal_set))); # Index for columns whose st. dev. isn't zero\n",
    "x = x[:, alldifferent_ind];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363×28 Matrix{Float64}:\n",
       " 1.0  1.0  1.0       0.868687  0.747475   …  0.343434   0.232323   1.0  1.0\n",
       " 1.0  1.0  0.0       0.0       0.0           0.171717   0.10101    1.0  1.0\n",
       " 1.0  1.0  0.0       0.505051  0.515152      0.131313   0.0707071  1.0  1.0\n",
       " 1.0  1.0  0.848485  0.868687  0.848485      0.232323   0.121212   1.0  1.0\n",
       " 1.0  1.0  0.757576  0.656566  0.606061      0.272727   0.151515   1.0  1.0\n",
       " 1.0  1.0  0.0       0.0       0.424242   …  0.505051   0.20202    1.0  1.0\n",
       " 1.0  1.0  1.0       0.0       0.0           0.494949   0.212121   1.0  1.0\n",
       " 1.0  1.0  0.575758  0.585859  0.494949      0.0909091  0.141414   1.0  1.0\n",
       " 1.0  1.0  0.0       0.0       0.0           0.0808081  0.151515   1.0  1.0\n",
       " 1.0  1.0  0.0       0.0       0.434343      0.363636   0.20202    1.0  1.0\n",
       " ⋮                                        ⋱             ⋮               \n",
       " 1.0  1.0  0.0       0.636364  0.616162      0.222222   0.0909091  1.0  1.0\n",
       " 1.0  1.0  0.0       0.0       0.0505051  …  0.272727   0.10101    1.0  1.0\n",
       " 1.0  1.0  0.0       0.606061  0.545455      0.525253   0.171717   1.0  1.0\n",
       " 1.0  1.0  0.878788  0.959596  0.59596       0.373737   0.151515   1.0  1.0\n",
       " 1.0  1.0  0.0       0.0       0.0           0.212121   0.171717   1.0  1.0\n",
       " 1.0  1.0  0.79798   0.818182  0.626263      0.323232   0.10101    1.0  1.0\n",
       " 1.0  1.0  1.0       0.222222  0.535354   …  0.020202   0.111111   1.0  1.0\n",
       " 1.0  1.0  0.919192  0.0       0.0           0.151515   0.191919   1.0  1.0\n",
       " 1.0  1.0  0.505051  0.252525  0.262626      0.262626   0.161616   1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# COLUMNS TO KEEP\n",
    "# ==================================================================\n",
    "#=Here, we care only about the columns in x::DataFrame whose elements \n",
    "are not all equal. If they are, the correlation is not defined b/c\n",
    "the standard deviation will be zero for columns whose elements\n",
    "are all the same =#\n",
    "if ishermitian(cor(x))\n",
    "    Σ_Z = LinearAlgebra.cholesky(cor(x));\n",
    "else\n",
    "    Σ_Z = factorize(cor(x));\n",
    "end\n",
    "M = Σ_Z.L;\n",
    "dim_M = size(M, 1);\n",
    "\n",
    "# ==================================================================\n",
    "# CORRELATION MATRIX\n",
    "# ==================================================================\n",
    "#= Determine a lower-triangular, nonsingular factorization M of the \n",
    "    the correlation matrix for Z such that MM' = Sigma_Z. =#\n",
    "if ishermitian(cor(x))\n",
    "    Σ_Z = LinearAlgebra.cholesky(cor(x));\n",
    "else\n",
    "    Σ_Z = factorize(cor(x));\n",
    "end\n",
    "M = Σ_Z.L;\n",
    "dim_M = size(M, 1);\n",
    "\n",
    "\n",
    "Random.seed!(12345);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_half = lp_solar[:, 1:size(lp_load, 2) ÷ 2];\n",
    "q_landing_probability = vec(left_half);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "8\n",
      "29\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "println(scenario_year)\n",
    "println(scenario_month)\n",
    "println(scenario_day)\n",
    "println(scenario_hour)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "syntax: incomplete: premature end of input",
     "output_type": "error",
     "traceback": [
      "syntax: incomplete: premature end of input\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\ks885\\Documents\\aa_research\\Modeling\\norta_scenarios\\copulas\\src\\011_test_solar_issue.ipynb:1"
     ]
    }
   ],
   "source": [
    "scenario_hour = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_date = DateTime(string(scenario_year) * \"-\" * string(scenario_month) * \"-\" * string(scenario_day) * \"T\" * string(scenario_hour));\n",
    "\n",
    "start_index = findfirst(isequal(start_date), unique_forecast_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×48 Matrix{Float64}:\n",
       "   5.0e-324        0.0           …    5.0e-324        2.0e-323\n",
       "   8.18978e-312    0.0                8.18978e-312    0.0\n",
       " NaN             NaN                NaN             NaN\n",
       "   0.0             8.18757e-312       8.18506e-312    0.0\n",
       "   0.0             6.36599e-314       1.4854e-313     0.0\n",
       "   0.0             5.0e-324      …    5.4e-323        0.0\n",
       "   0.0             0.0                0.0             0.0\n",
       " NaN             NaN                NaN             NaN\n",
       "   8.18506e-312    8.18831e-312       8.18832e-312    8.18879e-312\n",
       "   2.122e-314      1.4854e-313        6.36599e-314    1.4854e-313\n",
       "   ⋮                             ⋱                  \n",
       "   0.0             0.0                0.0             0.0\n",
       " NaN               8.18472e-312       8.18508e-312  NaN\n",
       "   8.18506e-312    8.18506e-312       8.18506e-312    8.18506e-312\n",
       "   2.122e-314      0.0                0.0             2.122e-314\n",
       "   5.0e-324        5.4e-323      …    5.0e-324        5.4e-323\n",
       "   8.18978e-312    0.0                0.0             8.18978e-312\n",
       " NaN             NaN                  8.18441e-312  NaN\n",
       "   0.0             0.0                8.18506e-312    8.18506e-312\n",
       "   0.0             0.0                0.0             2.122e-314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# PROBABILITY GENERATION LOOP\n",
    "# ==================================================================\n",
    "#= In certain cases, as in solar power, not all columns will be \n",
    "useful. Some will be discarded to avoid problems in the factorization\n",
    "of the correlation matrix. Here we check if the dimension n of the \n",
    "matrix M (n x n) is equal to the scenario length stipulated as 48.\n",
    "If it is not, the vector W will have its length adjusted to n. \n",
    "The variable allequal_ind stores the indices of the columns that \n",
    "were discarded. After the scenarios Y are generated, Y column dimension\n",
    "will be expanded and all-zero columns will be introduced in the \n",
    "location of the allequal_ind\n",
    "=#\n",
    "#Random.seed!(29031990)\n",
    "Random.seed!(12345)\n",
    "Y = Matrix{Float64}(undef, number_of_scenarios, scenario_length)\n",
    "\n",
    "# need_expansion = 0 # This is specially important for solar data with several columns whose st. dev. is zero\n",
    "# if dim_M != scenario_length\n",
    "#     original_scen_length = scenario_length\n",
    "#     upd_scenario_length = dim_M\n",
    "#     Y = Matrix{Float64}(undef, number_of_scenarios, upd_scenario_length)\n",
    "#     need_expansion = 1\n",
    "# else\n",
    "#     upd_scenario_length = scenario_length;\n",
    "# end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the trick is that the cholesky factorization gets rid of a lot of the excess stuff:\n",
    "\n",
    "* how?\n",
    "\n",
    "then\n",
    "\n",
    "* if I need q_solar_probability, how do I avoid the 1s?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, \n",
    "\n",
    "* if the solar is only forecasting for 28 hours, ... how do i ensure that the forecast is for 48 hours but puts the 28 correct hours appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `upd_scenario_length` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `upd_scenario_length` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\ks885\\Documents\\aa_research\\Modeling\\norta_scenarios\\copulas\\src\\011_test_solar_issue.ipynb:6"
     ]
    }
   ],
   "source": [
    "for nscen in 1:number_of_scenarios\n",
    "    # Set up normal distribution with mean 0 and sd equal to 1\n",
    "    d = Normal(0,1);\n",
    "\n",
    "    #Generate vector W = (W_1, ..., W_k) ~ iid standard normal\n",
    "    W = rand(d, upd_scenario_length);\n",
    "\n",
    "    # Create vector Z such that Z <- MW\n",
    "    Z = M * W;\n",
    "\n",
    "    #Compute the CDF of Z\n",
    "    #cdf_Z = sort(cdf.(d, Z));\n",
    "    cdf_Z = cdf.(d, Z);\n",
    "    \n",
    "    for k in 1:upd_scenario_length\n",
    "        #Apply the inverse CDF for X_k\n",
    "        # Y[nscen, k] = quantile(x[:, k], cdf_Z[k])\n",
    "        Y[nscen, k] = quantile(cdf_Z, q_landing_probability[start_index]);  \n",
    "        #= tells us the simulated quantile that we are at \\\n",
    "        from the simulation scenario probability distribution...\n",
    "        =#\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could define the 42-28=14 hours where there is for sure no solar output based on some process and manually change any 1 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×48 Matrix{Float64}:\n",
       "   5.0e-324        0.0           …    5.0e-324        2.0e-323\n",
       "   8.18978e-312    0.0                8.18978e-312    0.0\n",
       " NaN             NaN                NaN             NaN\n",
       "   0.0             8.18757e-312       8.18506e-312    0.0\n",
       "   0.0             6.36599e-314       1.4854e-313     0.0\n",
       "   0.0             5.0e-324      …    5.4e-323        0.0\n",
       "   0.0             0.0                0.0             0.0\n",
       " NaN             NaN                NaN             NaN\n",
       "   8.18506e-312    8.18831e-312       8.18832e-312    8.18879e-312\n",
       "   2.122e-314      1.4854e-313        6.36599e-314    1.4854e-313\n",
       "   ⋮                             ⋱                  \n",
       "   0.0             0.0                0.0             0.0\n",
       " NaN               8.18472e-312       8.18508e-312  NaN\n",
       "   8.18506e-312    8.18506e-312       8.18506e-312    8.18506e-312\n",
       "   2.122e-314      0.0                0.0             2.122e-314\n",
       "   5.0e-324        5.4e-323      …    5.0e-324        5.4e-323\n",
       "   8.18978e-312    0.0                0.0             8.18978e-312\n",
       " NaN             NaN                  8.18441e-312  NaN\n",
       "   0.0             0.0                8.18506e-312    8.18506e-312\n",
       "   0.0             0.0                0.0             2.122e-314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of notes\n",
    "* The are all zero as I expected\n",
    "* The diurnal pattern.... is that preserved? no i don't think so... let's print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"011a_print_scenarios.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print out Y to a csv\n",
    "CSV.write(\"011a_print_scenarios.csv\", DataFrame(Y, :auto), writeheader=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but if you don't comment out the dim size thing then Y is N by 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# PROBABILITY GENERATION LOOP\n",
    "# ==================================================================\n",
    "#= In certain cases, as in solar power, not all columns will be \n",
    "useful. Some will be discarded to avoid problems in the factorization\n",
    "of the correlation matrix. Here we check if the dimension n of the \n",
    "matrix M (n x n) is equal to the scenario length stipulated as 48.\n",
    "If it is not, the vector W will have its length adjusted to n. \n",
    "The variable allequal_ind stores the indices of the columns that \n",
    "were discarded. After the scenarios Y are generated, Y column dimension\n",
    "will be expanded and all-zero columns will be introduced in the \n",
    "location of the allequal_ind\n",
    "=#\n",
    "#Random.seed!(29031990)\n",
    "Random.seed!(12345)\n",
    "Y = Matrix{Float64}(undef, number_of_scenarios, scenario_length)\n",
    "\n",
    "need_expansion = 0 # This is specially important for solar data with several columns whose st. dev. is zero\n",
    "if dim_M != scenario_length\n",
    "    original_scen_length = scenario_length\n",
    "    upd_scenario_length = dim_M\n",
    "    Y = Matrix{Float64}(undef, number_of_scenarios, upd_scenario_length)\n",
    "    need_expansion = 1\n",
    "else\n",
    "    upd_scenario_length = scenario_length;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×28 Matrix{Float64}:\n",
       " 0.0           0.0           0.0           …  8.1894e-312   1.49874e-314\n",
       " 0.0           0.0           0.0              8.18941e-312  0.0\n",
       " 0.0           0.0           0.0              8.18941e-312  5.30499e-313\n",
       " 0.0           0.0           0.0              8.18941e-312  1.6e-322\n",
       " 0.0           0.0           0.0              8.18941e-312  8.16968e-312\n",
       " 0.0           0.0           0.0           …  8.1894e-312   1.6e-322\n",
       " 0.0           0.0           0.0              8.1894e-312   0.0\n",
       " 0.0           0.0           0.0              8.18941e-312  1.49874e-314\n",
       " 0.0           0.0           0.0              8.18941e-312  0.0\n",
       " 0.0           0.0           0.0              8.18941e-312  5.30499e-313\n",
       " ⋮                                         ⋱                \n",
       " 0.0           0.0           0.0              3.6586e-320   8.18941e-312\n",
       " 0.0           0.0           0.0              0.0           8.1894e-312\n",
       " 0.0           0.0           8.18523e-312     1.49874e-314  8.18941e-312\n",
       " 0.0           8.18523e-312  1.0e-323         0.0           8.1894e-312\n",
       " 8.18523e-312  1.0e-323      0.0           …  5.30499e-313  8.18941e-312\n",
       " 1.0e-323      0.0           0.0              3.304e-320    8.1894e-312\n",
       " 0.0           0.0           0.0              8.16968e-312  8.18941e-312\n",
       " 0.0           0.0           0.0              3.698e-320    8.1894e-312\n",
       " 0.0           0.0           0.0              0.0           8.1894e-312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nscen in 1:number_of_scenarios\n",
    "    # Set up normal distribution with mean 0 and sd equal to 1\n",
    "    d = Normal(0,1);\n",
    "\n",
    "    #Generate vector W = (W_1, ..., W_k) ~ iid standard normal\n",
    "    W = rand(d, upd_scenario_length);\n",
    "\n",
    "    # Create vector Z such that Z <- MW\n",
    "    Z = M * W;\n",
    "\n",
    "    #Compute the CDF of Z\n",
    "    #cdf_Z = sort(cdf.(d, Z));\n",
    "    cdf_Z = cdf.(d, Z);\n",
    "    \n",
    "    for k in 1:upd_scenario_length\n",
    "        #Apply the inverse CDF for X_k\n",
    "        # Y[nscen, k] = quantile(x[:, k], cdf_Z[k])\n",
    "        Y[nscen, k] = quantile(cdf_Z, q_landing_probability[start_index]);  \n",
    "        #= tells us the simulated quantile that we are at \\\n",
    "        from the simulation scenario probability distribution...\n",
    "        =#\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×28 Matrix{Float64}:\n",
       " 0.187397  0.187397  0.187397  0.187397  …  0.187397  0.187397  0.187397\n",
       " 0.260757  0.260757  0.260757  0.260757     0.260757  0.260757  0.260757\n",
       " 0.467003  0.467003  0.467003  0.467003     0.467003  0.467003  0.467003\n",
       " 0.247095  0.247095  0.247095  0.247095     0.247095  0.247095  0.247095\n",
       " 0.221442  0.221442  0.221442  0.221442     0.221442  0.221442  0.221442\n",
       " 0.423861  0.423861  0.423861  0.423861  …  0.423861  0.423861  0.423861\n",
       " 0.357687  0.357687  0.357687  0.357687     0.357687  0.357687  0.357687\n",
       " 0.337133  0.337133  0.337133  0.337133     0.337133  0.337133  0.337133\n",
       " 0.267158  0.267158  0.267158  0.267158     0.267158  0.267158  0.267158\n",
       " 0.323514  0.323514  0.323514  0.323514     0.323514  0.323514  0.323514\n",
       " ⋮                                       ⋱  ⋮                   \n",
       " 0.157193  0.157193  0.157193  0.157193     0.157193  0.157193  0.157193\n",
       " 0.364469  0.364469  0.364469  0.364469     0.364469  0.364469  0.364469\n",
       " 0.539027  0.539027  0.539027  0.539027     0.539027  0.539027  0.539027\n",
       " 0.135406  0.135406  0.135406  0.135406     0.135406  0.135406  0.135406\n",
       " 0.364102  0.364102  0.364102  0.364102  …  0.364102  0.364102  0.364102\n",
       " 0.368653  0.368653  0.368653  0.368653     0.368653  0.368653  0.368653\n",
       " 0.434124  0.434124  0.434124  0.434124     0.434124  0.434124  0.434124\n",
       " 0.399937  0.399937  0.399937  0.399937     0.399937  0.399937  0.399937\n",
       " 0.392197  0.392197  0.392197  0.392197     0.392197  0.392197  0.392197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But all of the scenarios are still identical... Is this the case if i were doing wind or load instead? Am I still misunderstanding the quantile function?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
