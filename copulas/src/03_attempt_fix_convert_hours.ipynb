{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\ks885\\Documents\\aa_research\\Modeling\\norta_scenarios\\copulas\\src\\copulas`\n"
     ]
    }
   ],
   "source": [
    "# Scenario Generation with Copulas \n",
    "# \n",
    "# Hugo S. de Araujo\n",
    "# Nov. 14th, 2022 | Mays Group | Cornell University\n",
    "################################################################################\n",
    "\n",
    "#=======================================================================\n",
    "PROJECT SETUP\n",
    "=======================================================================#\n",
    "using Pkg\n",
    "Pkg.activate(\"copulas\");\n",
    "Pkg.instantiate();\n",
    "# Import \"here\" function. Wrapper to allow easy path concatenation.\n",
    "include(joinpath(@__DIR__, \"functions\", \"fct_here.jl\"))\n",
    "\n",
    "# Import all required packages. \n",
    "begin\n",
    "    # using AWSS3\n",
    "    using CSV\n",
    "    using DataFrames\n",
    "    using Dates\n",
    "    using DelimitedFiles\n",
    "    using Distributions\n",
    "    using HDF5\n",
    "    using JuliaFormatter\n",
    "    using LaTeXStrings\n",
    "    using LinearAlgebra\n",
    "    using LinearSolve\n",
    "    #using Measures\n",
    "    using Random\n",
    "    using RCall\n",
    "    using Revise\n",
    "    using Statistics\n",
    "    using StatsBase\n",
    "    #using StatsPlots\n",
    "    using OhMyREPL\n",
    "    using Plots\n",
    "    #using PrettyTables\n",
    "    using Tables\n",
    "    using TSFrames\n",
    "    using TimeZones\n",
    "end\n",
    "\n",
    "# Include functions \n",
    "#= functions_dirpath = joinpath(pwd(),\"src\", \"functions\");\n",
    "function_paths = readdir(functions_dirpath, join=true);\n",
    "function_index = occursin.(\".jl\", function_paths);\n",
    "functions_only = function_paths[function_index];\n",
    "\n",
    "for str in functions_only\n",
    "    include(str)\n",
    "end =#\n",
    "\n",
    "include(here(\"src\", \"functions\", \"fct_bind_historical_forecast.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_compute_hourly_average_actuals.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_compute_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_hours_2018.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_ISO_standard.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_land_prob_to_data.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_generate_probability_scenarios.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_getplots.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_correlation_heatmap.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_historical_landing.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_historical_synthetic_autocorrelation.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_correlogram_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_scenarios_and_actual.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_read_h5_file.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_read_input_file.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_transform_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_write_percentiles.jl\"));\n",
    "#=======================================================================\n",
    "READ INPUT FILE\n",
    "=======================================================================#\n",
    "input_file_path = here(\"src\\\\copulas.txt\")\n",
    "\n",
    "# XXX Needs to be updated to be a hardcoded instead of reading in a text file\n",
    "data_type,\n",
    "scenario_length,\n",
    "number_of_scenarios,\n",
    "scenario_hour,\n",
    "scenario_day,\n",
    "scenario_month,\n",
    "scenario_year,\n",
    "read_locally,\n",
    "historical_load,\n",
    "forecast_load,\n",
    "historical_solar,\n",
    "forecast_da_solar,\n",
    "forecast_2da_solar,\n",
    "historical_wind,\n",
    "forecastd_da_wind,\n",
    "forecast_2da_wind,\n",
    "write_percentile = read_input_file(input_file_path);\n",
    "\n",
    "#=======================================================================\n",
    "READ INPUT DATA: ARPA-E PERFORM PROJECT H5 FILES\n",
    "=======================================================================#\n",
    "# Function that reads the .h5 file and binds the time index and the actuals/fore-\n",
    "# cast values into a single dataframe.\n",
    "\n",
    "# Load data\n",
    "load_actuals_raw = read_h5_file(here(\"data\", historical_load), \"load\");\n",
    "load_forecast_raw = read_h5_file(here(\"data\", \"ercot_BA_load_forecast_day_ahead_2018.h5\"), \"load\", false);\n",
    "\n",
    "# Solar data\n",
    "solar_actuals_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_actuals_Existing_2018.h5\"), \"solar\");\n",
    "solar_forecast_dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_forecast_day_ahead_existing_2018.h5\"), \"solar\", false);\n",
    "solar_forecast_2dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_forecast_2_day_ahead_existing_2018.h5\"), \"solar\", false);\n",
    "\n",
    "# Wind data\n",
    "wind_actuals_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_actuals_Existing_2018.h5\"), \"wind\");\n",
    "wind_forecast_dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_forecast_day_ahead_existing_2018.h5\"), \"wind\", false);\n",
    "wind_forecast_2dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_forecast_2_day_ahead_existing_2018.h5\"), \"wind\", false);\n",
    "\n",
    "#=======================================================================\n",
    "Compute the hourly average for the actuals data\n",
    "=======================================================================#\n",
    "# Load\n",
    "aux = compute_hourly_average_actuals(load_actuals_raw);\n",
    "load_actual_avg_raw = DataFrame();\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "load_actual_avg_raw[!, :time_index] = time_index;\n",
    "load_actual_avg_raw[!, :avg_actual] = avg_actual;\n",
    "\n",
    "# Solar\n",
    "aux = compute_hourly_average_actuals(solar_actuals_raw);\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "solar_actual_avg_raw = DataFrame();\n",
    "solar_actual_avg_raw[!, :time_index] = time_index;\n",
    "solar_actual_avg_raw[!, :avg_actual] = avg_actual;\n",
    "\n",
    "# Wind\n",
    "aux = compute_hourly_average_actuals(wind_actuals_raw);\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "wind_actual_avg_raw = DataFrame();\n",
    "wind_actual_avg_raw[!, :time_index] = time_index;\n",
    "wind_actual_avg_raw[!, :avg_actual] = avg_actual;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_forecast_raw;\n",
    "forecast_times = copy(data[:, :forecast_time])\n",
    "group_1 = forecast_times .<= DateTime(2018, 03, 11, 2); #from Jan. till Mar. 11\n",
    "group_2 = DateTime(2018, 03, 11, 2) .< forecast_times .<= DateTime(2018, 03, 25, 1); #from Mar. 11 to Mar. 25\n",
    "group_3 = DateTime(2018, 03, 25, 1) .< forecast_times .<= DateTime(2018, 10, 28, 2); #from Mar. 25 to Oct. 28\n",
    "group_4 = DateTime(2018, 10, 28, 2) .< forecast_times .<= DateTime(2018, 11, 04, 2); #from Oct. 28 to Nov. 04\n",
    "group_5 = forecast_times .>= DateTime(2018, 11, 04, 2); #from Nov. 04 ahead\n",
    "\n",
    "issue_times = copy(data[:, :issue_time])\n",
    "group_1y = issue_times .<= DateTime(2018, 03, 11, 2); #from Jan. till Mar. 11\n",
    "group_2y = DateTime(2018, 03, 11, 2) .< issue_times .<= DateTime(2018, 03, 25, 1); #from Mar. 11 to Mar. 25\n",
    "group_3y = DateTime(2018, 03, 25, 1) .< issue_times .<= DateTime(2018, 10, 28, 2); #from Mar. 25 to Oct. 28\n",
    "group_4y = DateTime(2018, 10, 28, 2) .< issue_times .<= DateTime(2018, 11, 04, 2); #from Oct. 28 to Nov. 04\n",
    "group_5y = issue_times .>= DateTime(2018, 11, 04, 2); #from Nov. 04 ahead\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do these accurately/fully subset - i.e. there are no lost hours?\n",
    "    * they should, I do not see how it would miss any hours....\n",
    "    * how would i check?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* are the groups the same length between forecast time and issue time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "println(length(group_1) == length(group_1y))\n",
    "println(length(group_2) == length(group_2y))\n",
    "println(length(group_3) == length(group_3y))\n",
    "println(length(group_4) == length(group_4y))\n",
    "println(length(group_5) == length(group_5y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> yes they are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh wait, they are all 17520 length that is why..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "println(group_1 == group_1y)\n",
    "println(group_2 == group_2y)\n",
    "println(group_3 == group_3y)\n",
    "println(group_4 == group_4y)\n",
    "println(group_5 == group_5y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: this might be problematic becasue then the different forecasts and issues, even when they align by row, might not be subtracted by the same hour change\n",
    "* what does that look like though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17520-element BitVector:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " â‹®\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
