{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\ks885\\Documents\\aa_research\\Modeling\\norta_scenarios\\copulas\\src\\copulas`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Scenario Generation with Copulas \n",
    "# \n",
    "# Hugo S. de Araujo\n",
    "# Nov. 14th, 2022 | Mays Group | Cornell University\n",
    "################################################################################\n",
    "\n",
    "#=======================================================================\n",
    "PROJECT SETUP\n",
    "=======================================================================#\n",
    "using Pkg\n",
    "Pkg.activate(\"copulas\");\n",
    "Pkg.instantiate();\n",
    "# Import \"here\" function. Wrapper to allow easy path concatenation.\n",
    "include(joinpath(@__DIR__, \"functions\", \"fct_here.jl\"))\n",
    "\n",
    "# Import all required packages. \n",
    "begin\n",
    "    # using AWSS3\n",
    "    using CSV\n",
    "    using DataFrames\n",
    "    using Dates\n",
    "    using DelimitedFiles\n",
    "    using Distributions\n",
    "    using HDF5\n",
    "    using JuliaFormatter\n",
    "    using LaTeXStrings\n",
    "    using LinearAlgebra\n",
    "    using LinearSolve\n",
    "    #using Measures\n",
    "    using Random\n",
    "    using RCall\n",
    "    using Revise\n",
    "    using Statistics\n",
    "    using StatsBase\n",
    "    #using StatsPlots\n",
    "    using OhMyREPL\n",
    "    using Plots\n",
    "    #using PrettyTables\n",
    "    using Tables\n",
    "    using TSFrames\n",
    "    using TimeZones\n",
    "end\n",
    "\n",
    "# Include functions \n",
    "#= functions_dirpath = joinpath(pwd(),\"src\", \"functions\");\n",
    "function_paths = readdir(functions_dirpath, join=true);\n",
    "function_index = occursin.(\".jl\", function_paths);\n",
    "functions_only = function_paths[function_index];\n",
    "\n",
    "for str in functions_only\n",
    "    include(str)\n",
    "end =#\n",
    "\n",
    "include(here(\"src\", \"functions\", \"fct_bind_historical_forecast.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_compute_hourly_average_actuals.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_compute_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_hours_2018.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_ISO_standard.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_convert_land_prob_to_data.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_generate_probability_scenarios.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_getplots.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_correlation_heatmap.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_historical_landing.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_historical_synthetic_autocorrelation.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_correlogram_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_plot_scenarios_and_actual.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_read_h5_file.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_read_input_file.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_transform_landing_probability.jl\"));\n",
    "include(here(\"src\", \"functions\", \"fct_write_percentiles.jl\"));\n",
    "#=======================================================================\n",
    "READ INPUT FILE\n",
    "=======================================================================#\n",
    "input_file_path = here(\"src\\\\copulas.txt\")\n",
    "\n",
    "# XXX Needs to be updated to be a hardcoded instead of reading in a text file\n",
    "data_type,\n",
    "scenario_length,\n",
    "number_of_scenarios,\n",
    "scenario_hour,\n",
    "scenario_day,\n",
    "scenario_month,\n",
    "scenario_year,\n",
    "read_locally,\n",
    "historical_load,\n",
    "forecast_load,\n",
    "historical_solar,\n",
    "forecast_da_solar,\n",
    "forecast_2da_solar,\n",
    "historical_wind,\n",
    "forecastd_da_wind,\n",
    "forecast_2da_wind,\n",
    "write_percentile = read_input_file(input_file_path);\n",
    "\n",
    "#=======================================================================\n",
    "READ INPUT DATA: ARPA-E PERFORM PROJECT H5 FILES\n",
    "=======================================================================#\n",
    "# Function that reads the .h5 file and binds the time index and the actuals/fore-\n",
    "# cast values into a single dataframe.\n",
    "\n",
    "# Load data\n",
    "load_actuals_raw = read_h5_file(here(\"data\", historical_load), \"load\");\n",
    "load_forecast_raw = read_h5_file(here(\"data\", \"ercot_BA_load_forecast_day_ahead_2018.h5\"), \"load\", false);\n",
    "\n",
    "# Solar data\n",
    "solar_actuals_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_actuals_Existing_2018.h5\"), \"solar\");\n",
    "solar_forecast_dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_forecast_day_ahead_existing_2018.h5\"), \"solar\", false);\n",
    "solar_forecast_2dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_solar_forecast_2_day_ahead_existing_2018.h5\"), \"solar\", false);\n",
    "\n",
    "# Wind data\n",
    "wind_actuals_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_actuals_Existing_2018.h5\"), \"wind\");\n",
    "wind_forecast_dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_forecast_day_ahead_existing_2018.h5\"), \"wind\", false);\n",
    "wind_forecast_2dayahead_raw = read_h5_file(here(\"data\", \"ercot_BA_wind_forecast_2_day_ahead_existing_2018.h5\"), \"wind\", false);\n",
    "\n",
    "#=======================================================================\n",
    "Compute the hourly average for the actuals data\n",
    "=======================================================================#\n",
    "# Load\n",
    "aux = compute_hourly_average_actuals(load_actuals_raw);\n",
    "load_actual_avg_raw = DataFrame();\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "load_actual_avg_raw[!, :time_index] = time_index;\n",
    "load_actual_avg_raw[!, :avg_actual] = avg_actual;\n",
    "\n",
    "# Solar\n",
    "aux = compute_hourly_average_actuals(solar_actuals_raw);\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "solar_actual_avg_raw = DataFrame();\n",
    "solar_actual_avg_raw[!, :time_index] = time_index;\n",
    "solar_actual_avg_raw[!, :avg_actual] = avg_actual;\n",
    "\n",
    "# Wind\n",
    "aux = compute_hourly_average_actuals(wind_actuals_raw);\n",
    "time_index = aux[:, :Index];\n",
    "avg_actual = aux[:, :values_mean];\n",
    "wind_actual_avg_raw = DataFrame();\n",
    "wind_actual_avg_raw[!, :time_index] = time_index;\n",
    "wind_actual_avg_raw[!, :avg_actual] = avg_actual;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take forecast time and issue time and subtract 6 hours to convert to Central US time.\n",
    "data = load_forecast_raw;\n",
    "df = copy(data);\n",
    "df[:,:forecast_time] = df[:,:forecast_time] .- Dates.Hour(6);\n",
    "df[:,:issue_time] = df[:,:issue_time] .- Dates.Hour(6);\n",
    "return df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* github copilot just wrote the timeshift/transformation in a different way.... would this fix the issue in the convert_hours?\n",
    "    * I could test it by running the original 02_debugging dayling_savings_time.ipynb and go to the end and do all the checks at the end..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upd_convert_hours_2018 (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a function to do this for all data\n",
    "function upd_convert_hours_2018(data, is_actual = true)\n",
    "    if is_actual\n",
    "        x = copy(data);\n",
    "        x[:,:time_index] = x[:,:time_index] .- Dates.Hour(6);\n",
    "        return x;\n",
    "    else\n",
    "        df = copy(data);\n",
    "        df[:,:forecast_time] = df[:,:forecast_time] .- Dates.Hour(6);\n",
    "        df[:,:issue_time] = df[:,:issue_time] .- Dates.Hour(6);\n",
    "        return df;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "load_actuals = upd_convert_hours_2018(load_actuals_raw);\n",
    "load_actual_avg = upd_convert_hours_2018(load_actual_avg_raw);\n",
    "load_forecast = upd_convert_hours_2018(load_forecast_raw, false);\n",
    "\n",
    "# Solar data\n",
    "solar_actuals = upd_convert_hours_2018(solar_actuals_raw);\n",
    "solar_actual_avg = upd_convert_hours_2018(solar_actual_avg_raw);\n",
    "solar_forecast_dayahead = upd_convert_hours_2018(solar_forecast_dayahead_raw, false);\n",
    "solar_forecast_2dayahead = upd_convert_hours_2018(solar_forecast_2dayahead_raw, false);\n",
    "\n",
    "# Wind data\n",
    "wind_actuals = upd_convert_hours_2018(wind_actuals_raw);\n",
    "wind_actual_avg = upd_convert_hours_2018(wind_actual_avg_raw);\n",
    "wind_forecast_dayahead = upd_convert_hours_2018(wind_forecast_dayahead_raw, false);\n",
    "wind_forecast_2dayahead = upd_convert_hours_2018(wind_forecast_2dayahead_raw, false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "BIND HOURLY HISTORICAL DATA WITH FORECAST DATA\n",
    "========================================================================#\n",
    "#= The binding is made by (\"forecast_time\" = \"time_index\"). This causes the \n",
    "average actual value to be duplicated, which is desired, given the # of rows\n",
    "in the load_forecast is double that of load_actual. To distinguish a \n",
    "one-day-ahead forecast from a two-day-ahead forecast, the column \"ahead_factor\"\n",
    "is introduced. Bind the day-ahead and two-day-ahead forecasts for wind and solar\n",
    "to get all the forecast data into one object as it is for load forecast =#\n",
    "    load_data = bind_historical_forecast(true,\n",
    "    load_actual_avg,\n",
    "    load_forecast);\n",
    "\n",
    "solar_data = bind_historical_forecast(false,\n",
    "    solar_actual_avg,\n",
    "    solar_forecast_dayahead,\n",
    "    solar_forecast_2dayahead);\n",
    "\n",
    "wind_data = bind_historical_forecast(false,\n",
    "    wind_actual_avg,\n",
    "    wind_forecast_dayahead,\n",
    "    wind_forecast_2dayahead);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "Landing probability\n",
    "=======================================================================#\n",
    "#= This section holds the calculation of the probability that the actual\n",
    "value was equaled or superior than the forecast percentiles for a given\n",
    "day. This is made possible by the estimation of an approximate CDF\n",
    "computed on the forecast percentiles. Once estimated, this function is\n",
    "used to find the \"landing probability\"; the prob. that the actual value\n",
    "is equal or greater than a % percentage of the forecast percentile.\n",
    "=#\n",
    "#include(here(\"src\", \"functions\", \"fct_compute_landing_probability.jl\"))\n",
    "landing_probability_load = compute_landing_probability(load_data);\n",
    "landing_probability_solar = compute_landing_probability(solar_data);\n",
    "landing_probability_wind = compute_landing_probability(wind_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "ADJUST LANDING PROBABILITY DATAFRAME\n",
    "=======================================================================#\n",
    "lp_load = transform_landing_probability(landing_probability_load);\n",
    "lp_solar = transform_landing_probability(landing_probability_solar);\n",
    "lp_wind = transform_landing_probability(landing_probability_wind);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = copy(landing_probability_load);\n",
    "# Sort data by issue time\n",
    "sort!(x, :issue_time);\n",
    "# Group data by issue time and count occurences in every group\n",
    "df = combine(groupby(x, [:issue_time]), DataFrames.nrow => :count);\n",
    "\n",
    "dst_filter = filter(:count => ==(50), df)\n",
    "forecast_time_dst = filter(row -> row.issue_time in dst_filter.issue_time, x).forecast_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are none with 50! Now check that there are all the ones we expect to be 48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "363*24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make sure that when we go through the process of filtering, we get 8712 hours out of it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363×48 transpose(::Matrix{Float64}) with eltype Float64:\n",
       " 0.888889  0.585859  0.545455  0.505051  …  0.878788  0.939394  0.919192\n",
       " 0.747475  0.777778  0.606061  0.606061     0.909091  0.878788  0.878788\n",
       " 1.0       0.939394  0.909091  1.0          0.434343  0.30303   0.323232\n",
       " 0.959596  0.828283  0.79798   0.888889     0.585859  0.575758  0.535354\n",
       " 0.353535  0.474747  0.575758  0.626263     0.333333  0.30303   0.323232\n",
       " 0.747475  0.707071  0.69697   0.757576  …  0.222222  0.20202   0.282828\n",
       " 0.525253  0.444444  0.393939  0.333333     0.818182  0.838384  0.838384\n",
       " 0.626263  0.686869  0.717172  0.656566     0.747475  0.757576  0.767677\n",
       " 0.818182  0.838384  0.919192  0.888889     0.515152  0.545455  0.515152\n",
       " 0.717172  0.686869  0.707071  0.737374     0.989899  0.979798  0.989899\n",
       " ⋮                                       ⋱  ⋮                   \n",
       " 0.868687  0.919192  0.949495  0.949495     0.515152  0.616162  0.525253\n",
       " 0.666667  0.676768  0.737374  0.676768  …  0.585859  0.555556  0.59596\n",
       " 0.646465  0.626263  0.575758  0.454545     0.444444  0.383838  0.383838\n",
       " 0.89899   0.89899   0.888889  0.858586     0.111111  0.111111  0.121212\n",
       " 0.363636  0.373737  0.282828  0.131313     0.434343  0.444444  0.40404\n",
       " 0.393939  0.393939  0.414141  0.424242     0.454545  0.505051  0.515152\n",
       " 0.363636  0.494949  0.515152  0.424242  …  0.717172  0.757576  0.585859\n",
       " 0.868687  0.808081  0.757576  0.686869     0.535354  0.707071  0.767677\n",
       " 0.444444  0.232323  0.10101   0.020202     0.727273  0.444444  0.414141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lp_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is 363 by 48 so it looks correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
